{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e14883",
   "metadata": {},
   "source": [
    "# Exercise 4 -Computer Vision\n",
    "\n",
    "\n",
    "### 4.1 - Face Detection and Tracking\n",
    "In this task you will implement face detection and tracking using OpenCV. Specifically we are utilizing Cascade classifiers which implements Viola-Jones detection algorithm.\n",
    "\n",
    "**Reference**\n",
    "- [OpenCV documentation on cascade classifier](https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html)\n",
    "\n",
    "### 4.1.1\n",
    "Execute the code below to initiate the cascadee classifier and the utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed45085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb82336",
   "metadata": {},
   "source": [
    "### 4.1.2\n",
    "\n",
    "Similar to Task 3, the first step is to obtain a frame from video file and pre-processing it. \n",
    "\n",
    "**Your task**\n",
    "\n",
    "Complete prep() function below which performs following using opencv and imutils libraries. The steps already implemented are marked with a tick \"âœ“\"\n",
    "\n",
    "- [x] Takes a frame from video feed as the input\n",
    "- [ ] Resize the frame while protecting the aspect ratio (width = 600) \n",
    "- [ ] Flip the image\n",
    "- [ ] Convert the frame to grayscale image\n",
    "- [x] Return grayscale image and resized image \n",
    "\n",
    "**References**\n",
    "\n",
    "- [imutils documentation](https://github.com/PyImageSearch/imutils#imutils)\n",
    "- [Fip an array with OpenCV](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441)\n",
    "- [color conversion with OpenCV](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce9f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    ## ToDo 4.1.2\n",
    "    #  1. resize using  imutils.resize()\n",
    "    img = imutils.resize(img, width=600)\n",
    "    \n",
    "    #  2. flip image vertically using cv2.flip()\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    #  3. convert to gray color using cv2.cvtColor()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return gray, img    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96848eab",
   "metadata": {},
   "source": [
    "### 4.1.3\n",
    "\n",
    "In 4.1.1 we initialized an instance of cascade classifier. Tracking a face can be broken down into 3 steps as below\n",
    "\n",
    "1. Detect Faces and ROIs\n",
    "\n",
    "   The cascade classifier has a member function which can detect faces of multiple scales in a given image. The area where a face is detected becomes a region of interest (ROI) for extracting meaningful information. \n",
    "\n",
    "    **References** : \n",
    "    [Multiscale face detection member function of cascade classifier](https://docs.opencv.org/3.4/d1/de5/classcv_1_1CascadeClassifier.html#a90fe1b7778bed4a27aa8482e1eecc116)\n",
    "\n",
    "\n",
    "2. Extract trackable features \n",
    "\n",
    "    Shi-Tomasi Corner Detector is an implementation in openCV which extracts information from the ROI input. The extracted information are points on the face which are are trackable across a sequence of moving frames (a video).\n",
    "\n",
    "    **References** : \n",
    "    [OpenCV Trackable feature extraction function(Shi-Tomasi Corner Detector)](https://docs.opencv.org/4.5.2/d4/d8c/tutorial_py_shi_tomasi.html)\n",
    "\n",
    "\n",
    "3. Calculate the optical flow\n",
    "\n",
    "    These trackable points are used to calculate the optical flow of the faces with calcOpticalFlowPyrLK() function. The tracking is visualized via OpenCV drawing tools.\n",
    "\n",
    "    **References** : \n",
    "    - [Optical Flow calculation](https://docs.opencv.org/4.5.3/d4/dee/tutorial_optical_flow.html)\n",
    "    - [OpenCV drawing functions](https://docs.opencv.org/4.5.2/dc/da5/tutorial_py_drawing_functions.html)\n",
    "\n",
    "**Your task**\n",
    "\n",
    "Complete the function which perfoms following\n",
    "\n",
    "- [x] Takes grayscale image and resized image as the input\n",
    "- [x] Detect faces in graycale image using cascade classifier. detectMultiscale() function returns detected faces as rectangles ( Top left x coordinate, Top left y coordinate, width, height)\n",
    "- [ ] Draw a rectangle around detected faces using OpenCV drawing functions\n",
    "- [ ] Slice a region of interest (ROI) from grayecale image corresponding to the detections\n",
    "- [x] Extract good features to track (p0), from OpenCV goodFeaturesToTrack() function.\n",
    "- [ ] Convert the array p0 from current format [[[x1,y1],[x2,y2],....]] to --> [[x1,y1],[x2,y2],....]. Tip : print p0 to observe current format\n",
    "- [ ] The points are located with respect to the ROI coordinates. Convert them to image coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trackable_points(gray,img):\n",
    "    # 1. Use the Cascade classifier to detect faces in the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    \n",
    "    # 2. Drawing Rectangles and Extracting ROIs\n",
    "    \n",
    "    # 2.1 Initialize an empty list to store trackable points\n",
    "    p0=[]\n",
    "    \n",
    "    # 2.2 Check if the faces are detected\n",
    "    if len(faces) != 0:\n",
    "        ## ToDO 4.1.3\n",
    "        # for (x,y,w,h) in faces:\n",
    "        #   draw rectang\n",
    "        #   slice ROI      \n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # 2.3 Draw a blue rectangle around the detected face\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            \n",
    "            # 2.4 Slice the grayscale image to extract ROI corresponding to the detected face\n",
    "            roi_gray = gray[y:y+h,x:x+w]\n",
    "            \n",
    "            # 2.5 Extract good features to track (p0) from each ROI\n",
    "            p0_roi = cv2.goodFeaturesToTrack(roi_gray, maxCorners=70, qualityLevel=0.001, minDistance=5)\n",
    "            p0.append(p0_roi)\n",
    "            \n",
    "        # ToDO 4.1.3\n",
    "        #  covert fromat of p0 to [[x1,y1],[x2,y2],....] \n",
    "        #  convert points from ROI to image coordinates\n",
    "        \n",
    "        # 3. Convert the array p0 from the format [[[x1, y1]], [[x2, y2]], ...] to [[x1, y1], [x2, y2], ...]\n",
    "        # Use list comprehension that flattens a list of lists\n",
    "        p0 = [item[0] for sublist in p0 for item in sublist]\n",
    "\n",
    "        # 4. Convert the points from ROI coordinates to image coordinates\n",
    "        p0 = [[x + x1, y + y1] for (x1, y1) in p0]\n",
    "        \n",
    "        # convert into float\n",
    "        p0 = np.float32(p0)\n",
    "   \n",
    "    return p0, faces, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6c1c4",
   "metadata": {},
   "source": [
    "**Your task**\n",
    "\n",
    "Complete the do_track_face() function which perfoms following\n",
    "\n",
    "- [x] Usecv2.calcOpticalFlowPyrLK()to calculate the optical flow for tracking face\n",
    "- [ ] Select the valid points from p1. Note that  isFound == 1 for valid points \n",
    "- [ ] Return the valid points as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6754539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_track_face(gray_prev, gray, p0):\n",
    "    # calculate the optical flow for tracking face\n",
    "    p1, isFound, err = cv2.calcOpticalFlowPyrLK(gray_prev, gray, p0, \n",
    "                                                            None,\n",
    "                                                            winSize=(31,31),\n",
    "                                                            maxLevel=10,\n",
    "                                                            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03),\n",
    "                                                            flags=cv2.OPTFLOW_LK_GET_MIN_EIGENVALS,\n",
    "                                                            minEigThreshold=0.00025)\n",
    "    \n",
    "    ## ToDo 4.1.3 - Select valid points from p1\n",
    "    \n",
    "    # Convert isFound to a 1D array (i.e., removing unnecessary dimensions)\n",
    "    isFound = np.squeeze(isFound)\n",
    "    \n",
    "    # Select only the points that are found and considered valid\n",
    "    valid_points = p1[isFound==1]\n",
    "\n",
    "    # return a numpy array of selected points from p1\n",
    "    return np.array(valid_points)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7a06b",
   "metadata": {},
   "source": [
    "# ROS Node for Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7632ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1704111385.394688191] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.401352781] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.609001262] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.638907090] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.643788185] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.663334290] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.739577764] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.787690027] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.854294301] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.963592743] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111385.990784878] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.058521820] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.174589978] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.193837935] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.270181951] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.366774167] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.393403305] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.467522224] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.613161206] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.681380365] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.687169139] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.732191539] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.788693003] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.913999856] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.980696786] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111386.987808588] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.055223955] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.265110029] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.271038717] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.276155403] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.332090513] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.389772953] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.509361581] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.586494621] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.594850732] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.656789756] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.817182625] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.861459709] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.867187975] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.942820260] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111387.995885923] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.106346327] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.169501548] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.188706620] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.256463910] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.482413175] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.487294515] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.491352779] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.531613920] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.587028822] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.661446477] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.805443625] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.864539866] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.870495967] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.928699273] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111388.989012301] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.108595078] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.162362889] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.185718115] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.254927314] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.473289638] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.480158006] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.485793829] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.528141792] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.588040585] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.676938921] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.788312336] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.804873349] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.884862012] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.949409134] [Face_Detection_Tracking]: Image callback function triggered!\n",
      "[INFO] [1704111389.989325883] [Face_Detection_Tracking]: Image callback function triggered!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FaceDetectionTrackingNode' object has no attribute 'stop_stream'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m\n\u001b[1;32m     89\u001b[0m         rclpy\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     82\u001b[0m     rclpy\u001b[38;5;241m.\u001b[39minit(args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m     face_detection_tracking \u001b[38;5;241m=\u001b[39m FaceDetectionTrackingNode()\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mrclpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_detection_tracking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     image_subscriber\u001b[38;5;241m.\u001b[39mterminate()\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py:222\u001b[0m, in \u001b[0;36mspin\u001b[0;34m(node, executor)\u001b[0m\n\u001b[1;32m    220\u001b[0m     executor\u001b[38;5;241m.\u001b[39madd_node(node)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mok():\n\u001b[0;32m--> 222\u001b[0m         \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     executor\u001b[38;5;241m.\u001b[39mremove_node(node)\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:739\u001b[0m, in \u001b[0;36mSingleThreadedExecutor.spin_once\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspin_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout_sec: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spin_once_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:736\u001b[0m, in \u001b[0;36mSingleThreadedExecutor._spin_once_impl\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    734\u001b[0m handler()\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler\u001b[38;5;241m.\u001b[39mexception() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m handler\u001b[38;5;241m.\u001b[39mexception()\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/task.py:239\u001b[0m, in \u001b[0;36mTask.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39miscoroutine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Execute a coroutine\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# The coroutine finished; store the result\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:437\u001b[0m, in \u001b[0;36mExecutor._make_handler.<locals>.handler\u001b[0;34m(entity, gc, is_shutdown, work_tracker)\u001b[0m\n\u001b[1;32m    434\u001b[0m gc\u001b[38;5;241m.\u001b[39mtrigger()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_coroutine(entity, arg)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     entity\u001b[38;5;241m.\u001b[39mcallback_group\u001b[38;5;241m.\u001b[39mending_execution(entity)\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:351\u001b[0m, in \u001b[0;36mExecutor._execute_timer\u001b[0;34m(self, tmr, _)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_timer\u001b[39m(\u001b[38;5;28mself\u001b[39m, tmr, _):\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m await_or_execute(tmr\u001b[38;5;241m.\u001b[39mcallback)\n",
      "File \u001b[0;32m/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py:107\u001b[0m, in \u001b[0;36mawait_or_execute\u001b[0;34m(callback, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m callback(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Call a normal function\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m, in \u001b[0;36mFaceDetectionTrackingNode.detect_track_face\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     76\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_stream\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FaceDetectionTrackingNode' object has no attribute 'stop_stream'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "\n",
    "import cv2\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "import numpy as np\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "\n",
    "# bridging\n",
    "bridge = CvBridge()\n",
    "FRAME_RATE = 30\n",
    "\n",
    "class FaceDetectionTrackingNode(Node):\n",
    "    def __init__(self):\n",
    "        # Constructor\n",
    "        super().__init__('Face_Detection_Tracking')\n",
    "\n",
    "        # Declare parameters\n",
    "        self.frame = []\n",
    "        self.p0 = [] # previous points\n",
    "        self.p1 = []\n",
    "        self.prev = 0\n",
    "        self.gray_prev = None  # previous frame\n",
    "\n",
    "        time_period = 0.1  # sec (for timer callback)\n",
    "        \n",
    "        # Make subscriber\n",
    "        self.subscriber_get_image = self.create_subscription( Image,'/image_raw', self.get_image,10)\n",
    "        \n",
    "        # Make timer for callback \n",
    "        self.timer = self.create_timer(time_period, self.detect_track_face)\n",
    "\n",
    "    def terminate(self):\n",
    "        self.get_logger().info('Video is being terminated!')\n",
    "    \n",
    "    def get_image(self, msg):\n",
    "        \"\"\"\n",
    "        callback function for sunscribing to raw_image topic \n",
    "        \"\"\"\n",
    "        self.get_logger().info(\"Image callback function triggered!\")\n",
    "        \n",
    "        # Convert ros2 image into OpenCV image\n",
    "        self.frame =  bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
    "        \n",
    "        return self.frame\n",
    "    \n",
    "    def detect_track_face(self):\n",
    "        \"\"\"\n",
    "        Callback function for face detection and tracking\n",
    "        \"\"\"\n",
    "            \n",
    "        time_elapsed = time.time() - self.prev\n",
    "\n",
    "        if time_elapsed > 1./FRAME_RATE:\n",
    "\n",
    "            self.prev = time.time()\n",
    "            gray, img = prep(self.frame)\n",
    "\n",
    "            self.p0, self.faces, img = get_trackable_points(gray,img)\n",
    "            self.gray_prev = gray.copy()\n",
    "\n",
    "            for (x,y,w,h) in self.faces:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                self.p1 = do_track_face(self.gray_prev, gray, self.p0)\n",
    "            \n",
    "            for i in self.p1:\n",
    "                cv2.drawMarker(img, (int(i[0]), int(i[1])),[255,0,0],0)\n",
    "            self.p0 = self.p1\n",
    "                       \n",
    "            cv2.imshow('Video feed', img)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord(\"q\"):\n",
    "                cv2.destroyAllWindows()\n",
    "                self.stop_stream()\n",
    "        \n",
    "\n",
    "def main(args=None):\n",
    "    try:\n",
    "        rclpy.init(args=None)\n",
    "        face_detection_tracking = FaceDetectionTrackingNode()\n",
    "        rclpy.spin(face_detection_tracking)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        image_subscriber.terminate()\n",
    "        image_subscriber.destroy_node()\n",
    "        rclpy.shutdown()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b4217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
